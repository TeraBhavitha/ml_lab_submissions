{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/fake_and_real_news.csv')\n",
        "\n",
        "# Drop NaN values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['label'] = label_encoder.fit_transform(df['label'])  # Converts 'Fake'/'Real' to 0/1\n",
        "\n",
        "# Splitting dataset\n",
        "X = df['Text']\n",
        "y = df['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorization\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "# Define classifiers\n",
        "classifiers = {\n",
        "    \"Naive Bayes\": MultinomialNB(),\n",
        "    \"SVM\": SVC(probability=True),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"AdaBoost\": AdaBoostClassifier(),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
        "    \"MLP\": MLPClassifier(max_iter=300)\n",
        "}\n",
        "\n",
        "# Hyperparameter tuning setup\n",
        "param_grid = {\n",
        "    \"SVM\": {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
        "    \"Decision Tree\": {'max_depth': [10, 20, 30]},\n",
        "    \"Random Forest\": {'n_estimators': [50, 100, 200]},\n",
        "    \"MLP\": {'hidden_layer_sizes': [(50,), (100,), (50,50)], 'activation': ['relu', 'tanh']}\n",
        "}\n",
        "\n",
        "# Train and evaluate models\n",
        "results = {}\n",
        "for name, model in classifiers.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    if name in param_grid:\n",
        "        search = RandomizedSearchCV(model, param_grid[name], n_iter=5, cv=3, scoring='accuracy', verbose=0, n_jobs=-1)\n",
        "        search.fit(X_train_tfidf, y_train)\n",
        "        model = search.best_estimator_\n",
        "    else:\n",
        "        model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test_tfidf)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{name} Accuracy: {acc:.4f}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    results[name] = acc\n",
        "\n",
        "# Display results\n",
        "print(\"\\nFinal Results:\")\n",
        "for model, acc in results.items():\n",
        "    print(f\"{model}: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d21jGhqGtrdR",
        "outputId": "c69d16c7-d2cc-4018-e134-51c7b567fb8c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Training Naive Bayes...\n",
            "Naive Bayes Accuracy: 0.9636\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.96       973\n",
            "           1       0.96      0.97      0.96      1007\n",
            "\n",
            "    accuracy                           0.96      1980\n",
            "   macro avg       0.96      0.96      0.96      1980\n",
            "weighted avg       0.96      0.96      0.96      1980\n",
            "\n",
            "Training SVM...\n",
            "SVM Accuracy: 0.9970\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       973\n",
            "           1       1.00      1.00      1.00      1007\n",
            "\n",
            "    accuracy                           1.00      1980\n",
            "   macro avg       1.00      1.00      1.00      1980\n",
            "weighted avg       1.00      1.00      1.00      1980\n",
            "\n",
            "Training Decision Tree...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 3 is smaller than n_iter=5. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.9985\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       973\n",
            "           1       1.00      1.00      1.00      1007\n",
            "\n",
            "    accuracy                           1.00      1980\n",
            "   macro avg       1.00      1.00      1.00      1980\n",
            "weighted avg       1.00      1.00      1.00      1980\n",
            "\n",
            "Training Random Forest...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 3 is smaller than n_iter=5. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.9990\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       973\n",
            "           1       1.00      1.00      1.00      1007\n",
            "\n",
            "    accuracy                           1.00      1980\n",
            "   macro avg       1.00      1.00      1.00      1980\n",
            "weighted avg       1.00      1.00      1.00      1980\n",
            "\n",
            "Training AdaBoost...\n",
            "AdaBoost Accuracy: 0.9995\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       973\n",
            "           1       1.00      1.00      1.00      1007\n",
            "\n",
            "    accuracy                           1.00      1980\n",
            "   macro avg       1.00      1.00      1.00      1980\n",
            "weighted avg       1.00      1.00      1.00      1980\n",
            "\n",
            "Training XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:58:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Accuracy: 0.9995\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       973\n",
            "           1       1.00      1.00      1.00      1007\n",
            "\n",
            "    accuracy                           1.00      1980\n",
            "   macro avg       1.00      1.00      1.00      1980\n",
            "weighted avg       1.00      1.00      1.00      1980\n",
            "\n",
            "Training MLP...\n",
            "MLP Accuracy: 0.9944\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       973\n",
            "           1       0.99      1.00      0.99      1007\n",
            "\n",
            "    accuracy                           0.99      1980\n",
            "   macro avg       0.99      0.99      0.99      1980\n",
            "weighted avg       0.99      0.99      0.99      1980\n",
            "\n",
            "\n",
            "Final Results:\n",
            "Naive Bayes: 0.9636\n",
            "SVM: 0.9970\n",
            "Decision Tree: 0.9985\n",
            "Random Forest: 0.9990\n",
            "AdaBoost: 0.9995\n",
            "XGBoost: 0.9995\n",
            "MLP: 0.9944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy joblib scikit-learn\n",
        "!pip install numpy==1.26.4 joblib scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUNd3Mwivnv6",
        "outputId": "ddb514fe-5c80-4ac0-b05a-49af3824f7a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Found existing installation: joblib 1.4.2\n",
            "Uninstalling joblib-1.4.2:\n",
            "  Successfully uninstalled joblib-1.4.2\n",
            "Found existing installation: scikit-learn 1.6.1\n",
            "Uninstalling scikit-learn-1.6.1:\n",
            "  Successfully uninstalled scikit-learn-1.6.1\n",
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting joblib\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting scikit-learn\n",
            "  Using cached scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Using cached scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "Installing collected packages: numpy, joblib, scikit-learn\n",
            "Successfully installed joblib-1.4.2 numpy-1.26.4 scikit-learn-1.6.1\n"
          ]
        }
      ]
    }
  ]
}